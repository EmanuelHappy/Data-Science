{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word 2 Vector model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLeaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # For preprocessing\n",
    "import pandas as pd  # For data handling\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict  # For word frequency\n",
    "\n",
    "import spacy  # For preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./../data/reddit/cm/Masculism_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Author</th>\n",
       "      <th>Score</th>\n",
       "      <th>Parent id</th>\n",
       "      <th>Publish Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c2lqouq</td>\n",
       "      <td>It is important to realize *why* so much atten...</td>\n",
       "      <td>AHumanThatListens</td>\n",
       "      <td>5</td>\n",
       "      <td>t3_knu87</td>\n",
       "      <td>2011-09-22 09:57:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c2lqp9j</td>\n",
       "      <td>There is also something else that's rarely bro...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>6</td>\n",
       "      <td>t3_knuah</td>\n",
       "      <td>2011-09-22 10:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c2lqpvn</td>\n",
       "      <td>I wish this subreddit good luck.  I hope this ...</td>\n",
       "      <td>junkeee999</td>\n",
       "      <td>6</td>\n",
       "      <td>t3_kntzz</td>\n",
       "      <td>2011-09-22 10:03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c2lqpwb</td>\n",
       "      <td>Good point. Men are not \"sexualizable,\" right?...</td>\n",
       "      <td>AHumanThatListens</td>\n",
       "      <td>4</td>\n",
       "      <td>t1_c2lqp9j</td>\n",
       "      <td>2011-09-22 10:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c2lqq9l</td>\n",
       "      <td>I think the more important point is that when ...</td>\n",
       "      <td>godlessaltruist</td>\n",
       "      <td>11</td>\n",
       "      <td>t1_c2lqouq</td>\n",
       "      <td>2011-09-22 10:05:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                            Comment  \\\n",
       "0  c2lqouq  It is important to realize *why* so much atten...   \n",
       "1  c2lqp9j  There is also something else that's rarely bro...   \n",
       "2  c2lqpvn  I wish this subreddit good luck.  I hope this ...   \n",
       "3  c2lqpwb  Good point. Men are not \"sexualizable,\" right?...   \n",
       "4  c2lqq9l  I think the more important point is that when ...   \n",
       "\n",
       "              Author  Score   Parent id         Publish Date  \n",
       "0  AHumanThatListens      5    t3_knu87  2011-09-22 09:57:33  \n",
       "1          [deleted]      6    t3_knuah  2011-09-22 10:00:01  \n",
       "2         junkeee999      6    t3_kntzz  2011-09-22 10:03:35  \n",
       "3  AHumanThatListens      4  t1_c2lqp9j  2011-09-22 10:03:42  \n",
       "4    godlessaltruist     11  t1_c2lqouq  2011-09-22 10:05:36  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID              0\n",
       "Comment         0\n",
       "Author          0\n",
       "Score           0\n",
       "Parent id       0\n",
       "Publish Date    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14249, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(doc):\n",
    "    # Lemmatizes and removes stopwords\n",
    "    # doc needs to be a spacy Doc object\n",
    "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
    "\n",
    "    # Too short comments aren't so useful in the training\n",
    "    if len(txt) > 2:\n",
    "        return ' '.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in df['Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to clean up everything: 6.42 mins\n",
      "CPU times: user 10min 51s, sys: 1min 41s, total: 12min 33s\n",
      "Wall time: 6min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_threads=-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14249, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = pd.DataFrame({'clean': txt})\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12734, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df_clean.dropna().drop_duplicates()\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [row.split() for row in df_clean['clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = Phrases(sent, min_count=30, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = bigram[sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21938"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['man',\n",
       " 'woman',\n",
       " 'think',\n",
       " 'feminist',\n",
       " 'people',\n",
       " 'like',\n",
       " 'rape',\n",
       " \"'\",\n",
       " 'say',\n",
       " 'thing',\n",
       " 'feminism']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=2,\n",
    "                     window=2,\n",
    "                     size=300,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.34 s, sys: 28 ms, total: 3.36 s\n",
      "Wall time: 3.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v_model.build_vocab(sentences, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 18s, sys: 1.11 s, total: 3min 19s\n",
      "Wall time: 1min 37s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8311380, 15990960)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.8259655833244324),\n",
       " ('structurally', 0.7188979983329773),\n",
       " ('victimize', 0.7095577716827393),\n",
       " ('gtman', 0.6805514097213745),\n",
       " ('gtwoman', 0.6772775650024414),\n",
       " ('supposedly', 0.6742631196975708),\n",
       " ('minimal', 0.6638935804367065),\n",
       " ('needy', 0.6635546088218689),\n",
       " ('lgbtq', 0.6602290868759155),\n",
       " ('receiver', 0.6591845750808716)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pua', 0.9059526920318604),\n",
       " ('incel', 0.8711636066436768),\n",
       " ('bitter', 0.8563239574432373),\n",
       " ('redpill', 0.8489885330200195),\n",
       " ('faction', 0.8479870557785034),\n",
       " ('homophobic', 0.8384590744972229),\n",
       " ('wary', 0.8337081670761108),\n",
       " ('vent', 0.8286869525909424),\n",
       " ('bash', 0.8209365606307983),\n",
       " ('vitriolic', 0.8129596710205078)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"mgtow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fling', 0.9197372794151306),\n",
       " ('moan', 0.9174047112464905),\n",
       " ('witty', 0.9127354621887207),\n",
       " ('flame', 0.9085283279418945),\n",
       " ('neckbeard', 0.9030858278274536),\n",
       " ('disgust', 0.900199830532074),\n",
       " ('excited', 0.8980779647827148),\n",
       " ('chill', 0.897413969039917),\n",
       " ('vitriolic', 0.8946410417556763),\n",
       " ('douchebag', 0.8921919465065002)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"incel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('movement', 0.8342776894569397),\n",
       " ('egalitarian', 0.8301292061805725),\n",
       " ('brand', 0.8225247859954834),\n",
       " ('anti_feminism', 0.8224219083786011),\n",
       " ('masculism', 0.8160293102264404),\n",
       " ('oppose', 0.796680748462677),\n",
       " ('pertain', 0.795570969581604),\n",
       " ('mrm', 0.7916226983070374),\n",
       " ('gender_equality', 0.7915030717849731),\n",
       " ('monolithic', 0.7891660928726196)]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"feminism\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6883935"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity(\"mra\", \"masculism\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71136"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity(\"mra\", \"mgtow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5894016"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity(\"mra\", \"incel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8711634"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity(\"incel\", \"mgtow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8489885"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity(\"redpill\", \"mgtow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71640015"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity(\"redpill\", \"mra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.018870939"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity(\"mra\", \"house\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8259655"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity(\"man\", \"woman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mra'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match(['incel', 'mgtow', 'mra', 'mensright'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsnescatterplot(model, word, list_names):\n",
    "    \"\"\" Plot in seaborn the results from the t-SNE reduction algorithm of the vectors of a query word,\n",
    "    its list of most similar words, and a list of words.\n",
    "    \"\"\"\n",
    "    arrays = np.empty((0, 300), dtype='f')\n",
    "    word_labels = [word]\n",
    "    color_list  = ['red']\n",
    "\n",
    "    # adds the vector of the query word\n",
    "    arrays = np.append(arrays, model.wv.__getitem__([word]), axis=0)\n",
    "    \n",
    "    # gets list of most similar words\n",
    "    close_words = model.wv.most_similar([word])\n",
    "    \n",
    "    # adds the vector for each of the closest words to the array\n",
    "    for wrd_score in close_words:\n",
    "        wrd_vector = model.wv.__getitem__([wrd_score[0]])\n",
    "        word_labels.append(wrd_score[0])\n",
    "        color_list.append('blue')\n",
    "        arrays = np.append(arrays, wrd_vector, axis=0)\n",
    "    \n",
    "    # adds the vector for each of the words from list_names to the array\n",
    "    for wrd in list_names:\n",
    "        wrd_vector = model.wv.__getitem__([wrd])\n",
    "        word_labels.append(wrd)\n",
    "        color_list.append('green')\n",
    "        arrays = np.append(arrays, wrd_vector, axis=0)\n",
    "        \n",
    "    # Reduces the dimensionality from 300 to 50 dimensions with PCA\n",
    "    reduc = PCA(n_components=19).fit_transform(arrays)\n",
    "    \n",
    "    # Finds t-SNE coordinates for 2 dimensions\n",
    "    np.set_printoptions(suppress=True)\n",
    "    \n",
    "    Y = TSNE(n_components=2, random_state=0, perplexity=15).fit_transform(reduc)\n",
    "    \n",
    "    # Sets everything up to plot\n",
    "    df = pd.DataFrame({'x': [x for x in Y[:, 0]],\n",
    "                       'y': [y for y in Y[:, 1]],\n",
    "                       'words': word_labels,\n",
    "                       'color': color_list})\n",
    "    \n",
    "    fig, _ = plt.subplots()\n",
    "    fig.set_size_inches(9, 9)\n",
    "    \n",
    "    # Basic plot\n",
    "    p1 = sns.regplot(data=df,\n",
    "                     x=\"x\",\n",
    "                     y=\"y\",\n",
    "                     fit_reg=False,\n",
    "                     marker=\"o\",\n",
    "                     scatter_kws={'s': 40,\n",
    "                                  'facecolors': df['color']\n",
    "                                 }\n",
    "                    )\n",
    "    \n",
    "    # Adds annotations one by one with a loop\n",
    "    for line in range(0, df.shape[0]):\n",
    "         p1.text(df[\"x\"][line],\n",
    "                 df['y'][line],\n",
    "                 '  ' + df[\"words\"][line].title(),\n",
    "                 horizontalalignment='left',\n",
    "                 verticalalignment='bottom', size='medium',\n",
    "                 color=df['color'][line],\n",
    "                 weight='normal'\n",
    "                ).set_size(15)\n",
    "\n",
    "    \n",
    "    plt.xlim(Y[:, 0].min()-50, Y[:, 0].max()+50)\n",
    "    plt.ylim(Y[:, 1].min()-50, Y[:, 1].max()+50)\n",
    "            \n",
    "    plt.title('t-SNE visualization for {}'.format(word.title()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
