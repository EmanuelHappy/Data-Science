{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import pickle \n",
    "\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import os, re, operator, warnings\n",
    "warnings.filterwarnings('ignore')  # Let's not pay heed to them right now\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./../w2v/df_clean.csv', 'rb') as fp:\n",
    "    df_clean = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = pd.read_csv('./../subreddits.csv')\n",
    "subreddits = sdf.values.tolist()\n",
    "for s in subreddits:\n",
    "        sub = str(s)[5:-5]\n",
    "\n",
    "        temp_df = pd.read_csv(f'./../data/reddit/cm/{sub}_comments.csv')\n",
    "        temp_df['subreddit'] = sub\n",
    "        if s == subreddits[0]:\n",
    "            df = temp_df\n",
    "        else:\n",
    "            df = df.append(temp_df, ignore_index=True)\n",
    "        print(f'added {sub}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.dropna().drop_duplicates()\n",
    "df_clean['subreddit'] = df['subreddit']\n",
    "df_clean['Date'] = df['Publish Date']\n",
    "df_clean['Parent id'] = df['Parent id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean[~df_clean.clean.str.contains(\"gt...\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_pickle(f\"df_clean_topic_model.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating topic model by community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"df_clean_topic_model.csv\", \"rb\") as fp:\n",
    "    df_clean = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MR_subreddits = ['LadyMRAs', 'FeMRADebates', 'Masculism', 'MensRants', 'FeMRA', 'MRActivism',\n",
    "                 'MensRightsLaw', 'MRRef']  # removed againstmansrights\n",
    "\n",
    "Incel_subreddits = ['askanincel', 'BlackPillScience', 'IncelsWithoutHate', 'Braincels']\n",
    "\n",
    "MGTOW_subreddits = ['MGTOW']\n",
    "\n",
    "RedPill_subreddits = ['RedPillParenting', 'TRPOffTopic', 'GEOTRP', 'thankTRP', 'redpillbooks',\n",
    "                      'becomeaman', 'RedPillWomen', 'TheBluePill', 'asktrp', 'TheRedPill']  # removed exredpill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_modeling(t_subreddits, sub):\n",
    "    df = df_clean.loc[df_clean['subreddit'].isin(t_subreddits)]\n",
    "    df = df.groupby('Parent id')['clean'].agg(lambda col: ' '.join(col))\n",
    "    \n",
    "    sub_sent = [row.split() for row in df]\n",
    "    sub_phrases = Phrases(sub_sent, min_count=30)\n",
    "    sub_bigram = Phraser(sub_phrases)\n",
    "    sub_sentences = sub_bigram[sub_sent]\n",
    "    \n",
    "    with open(f\"./data/{sub}_sentences.txt\", \"wb\") as fp:  # Pickling\n",
    "        pickle.dump(sub_sentences, fp)\n",
    "    print(f'{sub}_sentences.txt created')\n",
    "    \n",
    "    bigram = gensim.models.Phrases(sub_sentences)\n",
    "\n",
    "    dictionary = Dictionary(sub_sentences)\n",
    "    dictionary.save(f\"./data/{sub}_hdp_dictionary.dict\")\n",
    "    \n",
    "    print(f\"{sub} Dictionary saved as {sub}_hdp_dictionary.dict\")\n",
    "    corpus = [dictionary.doc2bow(text) for text in sub_sentences]\n",
    "    MmCorpus.serialize(f'./data/{sub}_hdp_corpus.mm', corpus)\n",
    "    print(f'Corpus saved as {sub} hdp_corpus.mm')\n",
    "\n",
    "    hdpmodel = HdpModel(corpus=corpus, id2word=dictionary)\n",
    "\n",
    "    hdpmodel.save(f'./data/{sub}_hdp_model_spacy.gensim')\n",
    "    print(f'{sub} hdp model created')\n",
    "\n",
    "    hdptopics = [[word for word, prob in topic] for topicid, topic in hdpmodel.show_topics(formatted=False)]\n",
    "\n",
    "    hdp_coherence = CoherenceModel(topics=hdptopics[:10], texts=sub_sentences,\n",
    "                                   dictionary=dictionary, window_size=10).get_coherence()\n",
    "\n",
    "    print(f\"The topic coherence is {hdp_coherence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MR_sentences.txt created\n",
      "MR Dictionary saved as MR_hdp_dictionary.dict\n",
      "Corpus saved as MR hdp_corpus.mm\n",
      "MR hdp model created\n",
      "The topic coherence is 0.1925351518078818\n",
      "Incel_sentences.txt created\n",
      "Incel Dictionary saved as Incel_hdp_dictionary.dict\n",
      "Corpus saved as Incel hdp_corpus.mm\n",
      "Incel hdp model created\n",
      "The topic coherence is 0.17516453392302694\n",
      "MGTOW_sentences.txt created\n",
      "MGTOW Dictionary saved as MGTOW_hdp_dictionary.dict\n",
      "Corpus saved as MGTOW hdp_corpus.mm\n",
      "MGTOW hdp model created\n",
      "The topic coherence is 0.19287052034094088\n",
      "RP_sentences.txt created\n",
      "RP Dictionary saved as RP_hdp_dictionary.dict\n",
      "Corpus saved as RP hdp_corpus.mm\n",
      "RP hdp model created\n",
      "The topic coherence is 0.19249689416454174\n"
     ]
    }
   ],
   "source": [
    "topic_modeling(MR_subreddits, 'MR')\n",
    "topic_modeling(Incel_subreddits, 'Incel')\n",
    "topic_modeling(MGTOW_subreddits, 'MGTOW')\n",
    "topic_modeling(RedPill_subreddits, 'RP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_topic_creation(model_df, community='reddit', years=[2014, 2015, 2016, 2017, 2018]):\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    sub = community\n",
    "    \n",
    "    for year in years:\n",
    "        \n",
    "        # Creating Sentences by time\n",
    "        time_df = model_df.loc[model_df['year'] == year]\n",
    "        time_df = time_df.groupby('Parent id')['clean'].agg(lambda col: ' '.join(col))\n",
    "        \n",
    "        sub_sent = [row.split() for row in time_df]\n",
    "        sub_phrases = Phrases(sub_sent, min_count=30)\n",
    "        sub_bigram = Phraser(sub_phrases)\n",
    "        sub_sentences = sub_bigram[sub_sent]\n",
    "\n",
    "        with open(f\"./data/{sub}_sentences_{year}.txt\", \"wb\") as fp:  # Pickling\n",
    "            pickle.dump(sub_sentences, fp)\n",
    "        print(f'{sub}_sentences_{year}.txt created')\n",
    "\n",
    "        bigram = gensim.models.Phrases(sub_sentences)\n",
    "\n",
    "        dictionary = Dictionary(sub_sentences)\n",
    "        dictionary.save(f\"./data/{sub}_hdp_dictionary_{year}.dict\")\n",
    "\n",
    "        print(f\"{sub} Dictionary saved as {sub}_hdp_dictionary_{year}.dict\")\n",
    "        corpus = [dictionary.doc2bow(text) for text in sub_sentences]\n",
    "        MmCorpus.serialize(f'./data/{sub}_hdp_corpus_{year}.mm', corpus)\n",
    "        print(f'Corpus saved as {sub}_hdp_corpus_{year}.mm')\n",
    "\n",
    "        '''hdpmodel = HdpModel(corpus=corpus, id2word=dictionary)\n",
    "\n",
    "        hdpmodel.save(f'./data/{sub}_hdp_model_spacy_{year}.gensim')\n",
    "        print(f'{sub} hdp model created as {sub}_hdp_model_spacy_{year}.gensim')\n",
    "\n",
    "        hdptopics = [[word for word, prob in topic] for topicid, topic in hdpmodel.show_topics(formatted=False)]\n",
    "\n",
    "        hdp_coherence = CoherenceModel(topics=hdptopics[:10], texts=sub_sentences,\n",
    "                                       dictionary=dictionary, window_size=10).get_coherence()\n",
    "\n",
    "        print(f\"The topic coherence is {hdp_coherence}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2014, 2015, 2016, 2017, 2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['Date'] = pd.to_datetime(df_clean['Date'])\n",
    "df_clean['year'] = df_clean['Date'].dt.year\n",
    "df_clean['year'] = df_clean['year'].mask(df_clean['year'] < 2015)\n",
    "df_clean['year'] = df_clean['year'].fillna(2014)\n",
    "df_clean = df_clean.astype({\"year\": int})\n",
    "df_clean.drop(columns='Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MR_df = df_clean.loc[df_clean['subreddit'].isin(MR_subreddits)]\n",
    "MGTOW_df = df_clean.loc[df_clean['subreddit'].isin(MGTOW_subreddits)]\n",
    "RedPill_df = df_clean.loc[df_clean['subreddit'].isin(RedPill_subreddits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MR_sentences_2014.txt created\n",
      "MR Dictionary saved as MR_hdp_dictionary_2014.dict\n",
      "Corpus saved as MR_hdp_corpus_2014.mm\n",
      "MR hdp model created as MR_hdp_model_spacy_2014.gensim\n",
      "The topic coherence is 0.21977563264363437\n",
      "MR_sentences_2015.txt created\n",
      "MR Dictionary saved as MR_hdp_dictionary_2015.dict\n",
      "Corpus saved as MR_hdp_corpus_2015.mm\n",
      "MR hdp model created as MR_hdp_model_spacy_2015.gensim\n",
      "The topic coherence is 0.2669650269251206\n",
      "MR_sentences_2016.txt created\n",
      "MR Dictionary saved as MR_hdp_dictionary_2016.dict\n",
      "Corpus saved as MR_hdp_corpus_2016.mm\n",
      "MR hdp model created as MR_hdp_model_spacy_2016.gensim\n",
      "The topic coherence is 0.20654154822571505\n",
      "MR_sentences_2017.txt created\n",
      "MR Dictionary saved as MR_hdp_dictionary_2017.dict\n",
      "Corpus saved as MR_hdp_corpus_2017.mm\n",
      "MR hdp model created as MR_hdp_model_spacy_2017.gensim\n",
      "The topic coherence is 0.19934594743999443\n",
      "MR_sentences_2018.txt created\n",
      "MR Dictionary saved as MR_hdp_dictionary_2018.dict\n",
      "Corpus saved as MR_hdp_corpus_2018.mm\n",
      "MR hdp model created as MR_hdp_model_spacy_2018.gensim\n",
      "The topic coherence is 0.1909323996204333\n",
      "MGTOW_sentences_2014.txt created\n",
      "MGTOW Dictionary saved as MGTOW_hdp_dictionary_2014.dict\n",
      "Corpus saved as MGTOW_hdp_corpus_2014.mm\n",
      "MGTOW hdp model created as MGTOW_hdp_model_spacy_2014.gensim\n",
      "The topic coherence is 0.2991624414600428\n",
      "MGTOW_sentences_2015.txt created\n",
      "MGTOW Dictionary saved as MGTOW_hdp_dictionary_2015.dict\n",
      "Corpus saved as MGTOW_hdp_corpus_2015.mm\n",
      "MGTOW hdp model created as MGTOW_hdp_model_spacy_2015.gensim\n",
      "The topic coherence is 0.2075624541103084\n",
      "MGTOW_sentences_2016.txt created\n",
      "MGTOW Dictionary saved as MGTOW_hdp_dictionary_2016.dict\n",
      "Corpus saved as MGTOW_hdp_corpus_2016.mm\n",
      "MGTOW hdp model created as MGTOW_hdp_model_spacy_2016.gensim\n",
      "The topic coherence is 0.19157749115029463\n",
      "MGTOW_sentences_2017.txt created\n",
      "MGTOW Dictionary saved as MGTOW_hdp_dictionary_2017.dict\n",
      "Corpus saved as MGTOW_hdp_corpus_2017.mm\n",
      "MGTOW hdp model created as MGTOW_hdp_model_spacy_2017.gensim\n",
      "The topic coherence is 0.23825448627757884\n",
      "MGTOW_sentences_2018.txt created\n",
      "MGTOW Dictionary saved as MGTOW_hdp_dictionary_2018.dict\n",
      "Corpus saved as MGTOW_hdp_corpus_2018.mm\n",
      "MGTOW hdp model created as MGTOW_hdp_model_spacy_2018.gensim\n",
      "The topic coherence is 0.18969030078385404\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3be297b97a05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtime_topic_creation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMR_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommunity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"MR\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtime_topic_creation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMGTOW_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommunity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"MGTOW\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtime_topic_creation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRedPill_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommunity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RP\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-48f6b2da3af3>\u001b[0m in \u001b[0;36mtime_topic_creation\u001b[0;34m(model_df, community, years)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0msub_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtime_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0msub_phrases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPhrases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_sent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0msub_bigram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPhraser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_phrases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0msub_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msub_bigram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msub_sent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/gensim/models/phrases.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, min_count, threshold, max_vocab_size, delimiter, progress_per, scoring, common_terms)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/gensim/models/phrases.py\u001b[0m in \u001b[0;36madd_vocab\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0;31m# counts collected in previous learn_vocab runs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         min_reduce, vocab, total_words = self.learn_vocab(\n\u001b[0;32m--> 544\u001b[0;31m             sentences, self.max_vocab_size, self.delimiter, self.progress_per, self.common_terms)\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_word_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/gensim/models/phrases.py\u001b[0m in \u001b[0;36mlearn_vocab\u001b[0;34m(sentences, max_vocab_size, delimiter, progress_per, common_terms)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcommon_terms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                     \u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlast_uncommon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                         \u001b[0mcomponents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_uncommon\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_between\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "time_topic_creation(MR_df, community=\"MR\")\n",
    "time_topic_creation(MGTOW_df, community=\"MGTOW\")\n",
    "time_topic_creation(RedPill_df, community=\"RP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RP_sentences_2014.txt created\n",
      "RP Dictionary saved as RP_hdp_dictionary_2014.dict\n",
      "Corpus saved as RP_hdp_corpus_2014.mm\n",
      "RP_sentences_2015.txt created\n",
      "RP Dictionary saved as RP_hdp_dictionary_2015.dict\n",
      "Corpus saved as RP_hdp_corpus_2015.mm\n",
      "RP_sentences_2016.txt created\n",
      "RP Dictionary saved as RP_hdp_dictionary_2016.dict\n",
      "Corpus saved as RP_hdp_corpus_2016.mm\n",
      "RP_sentences_2017.txt created\n",
      "RP Dictionary saved as RP_hdp_dictionary_2017.dict\n",
      "Corpus saved as RP_hdp_corpus_2017.mm\n",
      "RP_sentences_2018.txt created\n",
      "RP Dictionary saved as RP_hdp_dictionary_2018.dict\n",
      "Corpus saved as RP_hdp_corpus_2018.mm\n"
     ]
    }
   ],
   "source": [
    "time_topic_creation(RedPill_df, community=\"RP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA_time_model_creation(sub, years=[2014, 2015, 2016, 2017, 2018]):\n",
    "    for year in years:\n",
    "        with open(f\"./data/{sub}_sentences_{year}.txt\", \"rb\") as fp:   # Unpickling\n",
    "            sub_sentences = pickle.load(fp)\n",
    "            \n",
    "        dictionary = Dictionary.load(f'./data/{sub}_hdp_dictionary_{year}.dict')\n",
    "        corpus = MmCorpus(f'./data/{sub}_hdp_corpus_{year}.mm')\n",
    "                  \n",
    "        ldamodel = LdaModel(corpus=corpus, num_topics=15, id2word=dictionary)\n",
    "        ldamodel.save(f'./lda/{sub}_lda_model_{year}.gensim')\n",
    "        print(f'{sub} lda model created as {sub}_lda_model_{year}.gensim')\n",
    "\n",
    "        ldatopics = [[word for word, prob in topic] for topicid, topic in ldamodel.show_topics(formatted=False)]\n",
    "\n",
    "        lda_coherence = CoherenceModel(topics=ldatopics[:10], texts=sub_sentences,\n",
    "                                       dictionary=dictionary, window_size=10).get_coherence()\n",
    "\n",
    "        print(f\"The topic coherence is {lda_coherence}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MR lda model created as MR_lda_model_2014.gensim\n",
      "The topic coherence is 0.4303349630739578\n",
      "\n",
      "MR lda model created as MR_lda_model_2015.gensim\n",
      "The topic coherence is 0.39077168604890067\n",
      "\n",
      "MR lda model created as MR_lda_model_2016.gensim\n",
      "The topic coherence is 0.35329469574491223\n",
      "\n",
      "MR lda model created as MR_lda_model_2017.gensim\n",
      "The topic coherence is 0.42222909316824825\n",
      "\n",
      "MR lda model created as MR_lda_model_2018.gensim\n",
      "The topic coherence is 0.39659447502140033\n",
      "\n",
      "MGTOW lda model created as MGTOW_lda_model_2014.gensim\n",
      "The topic coherence is 0.3123680152310265\n",
      "\n",
      "MGTOW lda model created as MGTOW_lda_model_2015.gensim\n",
      "The topic coherence is 0.36693680812053986\n",
      "\n",
      "MGTOW lda model created as MGTOW_lda_model_2016.gensim\n",
      "The topic coherence is 0.38146385739503885\n",
      "\n",
      "MGTOW lda model created as MGTOW_lda_model_2017.gensim\n",
      "The topic coherence is 0.3828453513299753\n",
      "\n",
      "MGTOW lda model created as MGTOW_lda_model_2018.gensim\n",
      "The topic coherence is 0.3951469472043319\n",
      "\n",
      "RP lda model created as RP_lda_model_2014.gensim\n",
      "The topic coherence is 0.42518514188058126\n",
      "\n",
      "RP lda model created as RP_lda_model_2015.gensim\n",
      "The topic coherence is 0.4043820008508815\n",
      "\n",
      "RP lda model created as RP_lda_model_2016.gensim\n",
      "The topic coherence is 0.39023903596180437\n",
      "\n",
      "RP lda model created as RP_lda_model_2017.gensim\n",
      "The topic coherence is 0.42548353989107135\n",
      "\n",
      "RP lda model created as RP_lda_model_2018.gensim\n",
      "The topic coherence is 0.4796544532360961\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LDA_time_model_creation('MR')\n",
    "LDA_time_model_creation('MGTOW')\n",
    "LDA_time_model_creation('RP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA_model_creation(sub):\n",
    "        \n",
    "    with open(f\"./data/{sub}_sentences.txt\", \"rb\") as fp:   # Unpickling\n",
    "            sub_sentences = pickle.load(fp)\n",
    "            \n",
    "    dictionary = Dictionary.load(f'./data/{sub}_hdp_dictionary.dict')\n",
    "    corpus = MmCorpus(f'./data/{sub}_hdp_corpus.mm')\n",
    "\n",
    "    ldamodel = LdaModel(corpus=corpus, num_topics=15, id2word=dictionary)\n",
    "    ldamodel.save(f'./lda/{sub}_lda_model.gensim')\n",
    "    print(f'{sub} lda model created as {sub}_lda_model.gensim')\n",
    "\n",
    "    ldatopics = [[word for word, prob in topic] for topicid, topic in ldamodel.show_topics(formatted=False)]\n",
    "\n",
    "    lda_coherence = CoherenceModel(topics=ldatopics[:10], texts=sub_sentences,\n",
    "                                   dictionary=dictionary, window_size=10).get_coherence()\n",
    "\n",
    "    print(f\"The topic coherence is {lda_coherence}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MR lda model created as MR_lda_model.gensim\n",
      "The topic coherence is 0.44454499861981916\n",
      "\n",
      "MGTOW lda model created as MGTOW_lda_model.gensim\n",
      "The topic coherence is 0.4208849264427322\n",
      "\n",
      "RP lda model created as RP_lda_model.gensim\n",
      "The topic coherence is 0.38998915297146425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LDA_model_creation('MR')\n",
    "LDA_model_creation('MGTOW')\n",
    "LDA_model_creation('RP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incel lda model created as Incel_lda_model.gensim\n",
      "The topic coherence is 0.4343119597329652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LDA_model_creation('Incel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.wrappers.dtmmodel import DtmModel\n",
    "RP_corpus = MmCorpus('./data/RP_hdp_corpus.mm')\n",
    "RP_dict =  Dictionary.load('./data/RP_hdp_dictionary.dict')\n",
    "RP_time_seq = []\n",
    "for year in years:\n",
    "    c = MmCorpus(f'./data/RP_hdp_corpus_{year}.mm')\n",
    "    RP_time_seq.append(len(c))\n",
    "RP_time_seq.append(len(RP_corpus) - sum(RP_time_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_path = \"./data/dtm/dtm-linux64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "RP_model = DtmModel(dtm_path, RP_corpus, RP_time_seq, num_topics=10,\n",
    "                 id2word=RP_dict, initialize_lda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "RP_model.save(\"./lda/RP_dtm.gensim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
