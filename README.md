# Data-Science
This is the beginning of my scientific initiation on hate speech identification.

First week:
  I made an programm that get submissions and comments from an subreddit.
  
Second week:
  I improved the project, splitting the program in two: submissions and comments, so became easier to collect more data. Also, I collected the informations of 26 subreddits this time.

Third week:
  This week was just a study of good programming practices, in which I comment correctly on my script and turn it in something more scalable.
  
 Fourth week:
  Using matplotlib, pandas and other modeles I made an script to collect some data, like the subs activity, theyr polarity and theyer hate
  
 Fifth week:
    Using networkx I made an network correlating nodes with the subreddits, the size of each node with theyr degree and the edges with the number of commom authors
 
Sixth week:
  I just run my code in the Hydras, finishing the collect of the data and plotting my anterior graphs.
  
 Seventh week:
  Start to make some topic models and finishing the first data science book study
 
 Eighth week:
  I've run my topic model code, improve the graphs styles and run the emotion analysis for "good emotions". I'm also made some notebooks to explore the migrations between communities.
 
 Ninth week:
  Using the networkx learned before, I made a grid plot to visualyse the evolution of the reddits communities and how they where correlated
